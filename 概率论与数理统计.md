# 随机事件与概率

- 常用公式

    - 加法
    
        $$
        P(A \cup B) = P(A) + P(B) - P(AB)
        $$

        $$
        P(A \cup B \cup C) = P(A) + P(B) + P(C) - P(AB) - P(AC) - P(BC) + P(ABC)
        $$

    - 减法

        $$
        P(A - B) = P(A) - P(AB)
        $$


- 条件概率

    $$
    P(A|B) = \frac{P(AB)}{P(B)}
    $$

- 全概率公式
  
    若 $\sum_{i=1}^{n} B_i = \Omega$，则

    $$
    P(A) = \sum_{i=1}^{n} P(A|B_i)P(B_i)
    $$

- 贝叶斯公式

    若 $\sum_{i=1}^{n} B_i = \Omega$，则

    $$
    P(B_i|A) = \frac{P(A|B_i)P(B_i)}{P(A)} = \frac{P(A|B_i)P(B_i)}{\sum_{j=1}^{n} P(A|B_j)P(B_j)}
    $$

    简化为

    $$
    P(B|A) = \frac{P(A|B)P(B)}{P(A)}
    $$

- 独立事件
    若 $A$ 和 $B$ 独立，则
    $$
    P(AB) = P(A)P(B) \\
    P(A|B) = P(A) \\
    P(B|A) = P(B)
    $$

> 此时 $\overline{A},B$ 、 $\overline{B},A$ 和 $\overline{B},\overline{A}$ 也相互独立


**古典概型略**

# 一维随机变量及其分布函数

## 离散型随机变量及其分布

- 两点分布

    $$
    P(X = 0) = 1- p, \quad P(X = 1) = p
    $$

- 二项分布 $B(n,p)$

    $$
    P(X = k) = C_n^k p^k (1-p)^{n-k}, \quad k = 0, 1, \ldots, n
    $$

- 松柏分布 $P(\lambda)$

    $$
    P(X = k) =\frac{\lambda^k e^{-\lambda}}{k!}, \quad k = 0, 1, 2, \ldots
    $$

- 超几何分布 $H(n,m,N)$

    $$
    P(X = k) = \frac{C_m^k C_{N-m}^{n-k}}{C_N^n}, \quad k = 0, 1, \ldots, n
    $$

- 松柏定理

    当 $n \to \infty$ 时，令 $\lambda = np$，则二项分布 $B(n,p)$ 近似于泊松分布 $P(\lambda)$。

    $$
    \lim_{n \to \infty} B(n,p) = P(np)
    $$

离散型随机变量的分布函数为

$$
F(x) = P(X \leq x) = \sum_{k \leq x} P(X = k)
$$

可以得到

$$
P(a < X \leq b) = F(b) - F(a)
$$

## 连续型随机变量及其分布

若存在非负可积函数 $f(x)$，使得随机变量 $X$ 取值于任意区间 $[a,b]$ 上的概率为

$$
P(a \leq X \leq b) = \int_a^b f(x) dx
$$

则称 $f(x)$ 为随机变量 $X$ 的概率密度函数，简称密度函数。

规范性条件：
1. $f(x) \geq 0, \forall x \in \mathbb{R}$
2. $\int_{-\infty}^{+\infty} f(x) dx = 1$

- 均匀分布 $U(a,b)$

    $$
    f(x) = \begin{cases}
    \frac{1}{b-a}, & a \leq x \leq b \\
    0, & \text{otherwise}
    \end{cases}
    $$

- 指数分布 $E(\lambda)$

    $$
    f(x) = \begin{cases}
    \lambda e^{-\lambda x}, & x \geq 0 \\
    0, & \text{otherwise}
    \end{cases}
    $$

- 正态分布 $N(\mu, \sigma^2)$

    $$
    f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
    $$

    标准正态分布 $N(0,1)$ 的密度函数为

    $$
    f(x) = \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}}
    $$

连续型随机变量的分布函数为

$$
F(x) = P(X < x) = \int_{-\infty}^x f(t) dt
$$

同样有

$$
P(a < X < b) = F(b) - F(a)
$$

> 由于连续性随机变量单点概率为0的特点，因此这里的比较符号可任意使用 $\leq$ 或 $<$。


# 二维随机变量及其分布函数



二维随机变量的分布函数通常又称为**联合分布函数**或**联合密度函数**

$$
F(x,y) = P(X \leq x, Y \leq y)
$$

- 联合分布函数的性质

    1. $F(x,y)$ 是非递减函数
    2. $\lim_{x \to -\infty} F(x,y) = 0, \forall y$
    3. $\lim_{y \to -\infty} F(x,y) = 0, \forall x$
    4. $\lim_{x \to +\infty} F(x,y) = P(Y \leq y), \forall y$
    5. $\lim_{y \to +\infty} F(x,y) = P(X \leq x), \forall x$
    6. $\lim_{x \to +\infty, y \to +\infty} F(x,y) = 1$
    7. 对于四个实数 $a \leq b, c \leq d$，有
    
    $$
    F(b,d) - F(a,d) - F(b,c) + F(a,c) = P(a \leq X \leq b, c \leq Y \leq d) \geq 0
    $$

## 边缘分布函数

对于二维随机变量 $(X,Y)$，其边缘分布函数为

$$
F_X(x) = P(X \leq x) = \lim_{y \to +\infty} F(x,y) \\
F_Y(y) = P(Y \leq y) = \lim_{x \to +\infty} F(x,y) \\
$$


## 条件分布函数

对于二维随机变量 $(X,Y)$，其条件密度函数为

$$
f_{Y|X}(y|x) = \frac{f(x,y)}{f_X(x)} \\
f_{X|Y}(x|y) = \frac{f(x,y)}{f_Y(y)}
$$

其条件分布函数为

$$
F_{Y|X}(y|x) = \frac{F(x,y)}{F_X(x)} \\
F_{X|Y}(x|y) = \frac{F(x,y)}{F_Y(y)}
$$

## 二维离散型随机变量

- 对于二维离散型随机变量 $(X,Y)$，其分布律为

$$
P(X = x_i, Y = y_j) = P(X = x_i \cap Y = y_j)=p_{ij}
$$

- 其联合分布函数为
$$
F(x,y) = P(X \leq x, Y \leq y) = \sum_{x_i \leq x} \sum_{y_j \leq y} p_{ij}
$$


- 其边缘分布律为

$$
F_X(x) = F(x, +\infty) = \sum_{y_j} p_{X,Y}(x,y_j) \\
F_Y(y) = F(+\infty, y) = \sum_{x_i} p_{X,Y}(x_i,y)
$$

则有

$$
P(X = x_i) = p_X(x_i) = \sum_{y_j} p_{X,Y}(x_i,y_j) \\
P(Y = y_j) = p_Y(y_j) = \sum_{x_i} p_{X,Y}(x_i,y_j)
$$

- 离散型随机变量独立性判别条件

若 $X, Y$ 独立，则

$$
f(x,y) = f_X(x) f_Y(y) \tag 1
$$

- 条件分布律为

$$
P(Y = y_j | X = x_i) = \frac{P(X = x_i, Y = y_j)}{P(X = x_i)} = \frac{p_{ij}}{p_X(x_i)} \\
P(X = x_i | Y = y_j) = \frac{P(X = x_i, Y = y_j)}{P(Y = y_j)} = \frac{p_{ij}}{p_Y(y_j)}
$$


## 二维连续型随机变量

- 对于二维连续型随机变量 $(X,Y)$，其联合分布函数为

$$
F(x,y) = P(X \leq x, Y \leq y) = \int_{-\infty}^x \int_{-\infty}^y f(u,v) dv du \\
\frac{\partial^2 F(x,y)}{\partial x \partial y} = f(x,y)
$$

$f(x,y)$ 为其联合密度函数，满足

$$
f(x,y) \geq 0, \forall x,y \in \mathbb{R} \\
\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} f(x,y) dx dy = 1 \\
P\{(X,Y) \in D\} = \int_D f(x,y) dx dy
$$

- 其边缘分布函数为

$$
F_X(x) = P(X \leq x) = F(x, +\infty) =  \int_{-\infty}^x \left(\int_{-\infty}^{+\infty} f(u,y) dy\right) du \\
F_Y(y) = P(Y \leq y) = F(+\infty, y) =  \int_{-\infty}^y \left(\int_{-\infty}^{+\infty} f(x,v) dx\right) dy
$$

若 $X, Y$ 为随机变量，则其概率密度函数为

$$
f_X(x) = \int_{-\infty}^{+\infty} f(x,y) dy \\
f_Y(y) = \int_{-\infty}^{+\infty} f(x,y) dx
$$

- 连续性随机变量的独立性判别条件

同式(1)

- 条件概率密度函数为
  
$$
f_{Y|X}(y|x) = \frac{f(x,y)}{f_X(x)} \\
f_{X|Y}(x|y) = \frac{f(x,y)}{f_Y(y)}
$$

则条件分布函数为

$$
F_{Y|X}(y|x) = \frac{F(x,y)}{F_X(x)} = \int_{-\infty}^y f_{Y|X}(v|x) dv \\
F_{X|Y}(x|y) = \frac{F(x,y)}{F_Y(y)} = \int_{-\infty}^x f_{X|Y}(u|y) du
$$

## 连续型随机变量函数的分布

### 1. $Z=X+Y$

其分布函数为

$$
F_Z(z)=P(Z \leq z)=\iint\limits_{x+y \leq z}f(u,v)\mathrm{d}u\mathrm{d}v
$$

化简该二重积分，得到

$$
F_Z(z)=\int_{-\infty}^{+\infty}\left[\int_{-\infty}^zf(t-y,y)\mathrm{d}y\right]\mathrm{d}t
$$

$$
f_Z(z)=F'_Z(z)=\int^{+\infty}_{-\infty}f(z-y,y)\mathrm{d}y=\int^{+\infty}_{-\infty}f(x,z-x)\mathrm{d}x   \tag 2
$$

当 $X, Y$ 独立时，式（2）可化为卷积公式，即

$$
f_Z(z)=\int_{-\infty}^{+\infty}f_X(x)f_Y(z-x)\mathrm{d}x
$$

### 2. $M=\max(X,Y)$ 及 $N=\min(X,Y)$

其分布函数为

$$
F_M(z)=P(M \leq z)=P(X \leq z, Y \leq z)=P(X \leq z)P(Y \leq z)=F_X(z)F_Y(z)
$$

$$
F_N(z)=P(N \leq z)=1-P(N>z)=1-P(X > z, Y > z)\\
=1-P(X > z)P(Y > z)=1-[1-F_X(z)][1-F_Y(z)]
$$

对于多维连续随机变量 $X_1, X_2, X_3 ... X_i$ ，其满足

$$
F_{M}(z) = \prod_{i=1}^{n} F_{X_i}(z) \\
F_{N}(z) = 1 - \prod_{i=1}^{n} [1 - F_{X_i}(z)]
$$


# 随机变量的数字特征

## 数学期望

- 离散型随机变量

    对于离散型随机变量 $X$，其数学期望为

    $$
    E(X) = \sum_{x_i} x_i P(X = x_i)
    $$

- 连续型随机变量

    对于连续型随机变量 $X$，其数学期望为

    $$
    E(X) = \int_{-\infty}^{+\infty} x f(x) dx
    $$

### 随机变量函数的数学期望

- 离散型随机变量

    对于离散型随机变量 $X$，其函数 $g(X)$ 的数学期望为

    $$
    E(g(X)) = \sum_{x_i} g(x_i) P(X = x_i)
    $$

    对于二维离散型随机变量 $(X,Y)$，其函数 $g(X,Y)$ 的数学期望为

    $$
    E(g(X,Y)) = \sum_{x_i} \sum_{y_j}
    g(x_i, y_j) P(X = x_i, Y = y_j)
    $$

- 连续型随机变量

    对于连续型随机变量 $X$，其函数 $g(X)$ 的数学期望为

    $$
    E(g(X)) = \int_{-\infty}^{+\infty} g(x) f(x) dx
    $$

    对于二维连续型随机变量 $(X,Y)$，其函数 $g(X,Y)$ 的数学期望为

    $$
    E(g(X,Y)) = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} g(x,y) f(x,y) dx dy
    $$

### 数学期望的性质

1. 设 $C$ 为常数，则

    $$
    E(C) = C
    $$

2. 设 $X$ 为随机变量，$C$ 为常数，则

    $$
    E(CX) = CE(X)
    $$

3. 设 $X, Y$ 为随机变量，则
    $$
    E(X + Y) = E(X) + E(Y)
    $$

4. 设 $X, Y$ 为独立随机变量，则

    $$
    E(XY) = E(X)E(Y)
    $$

## 方差

$$
D(X)=E[X-E(X)]^2=E(X^2)-[E(X)]^2
$$

### 方差的性质

1. 设 $C$ 为常数，则

    $$
    D(C) = 0
    $$

2. $D(X) \leq 0$ , $D(X)=0$ 的充要条件为存在常数 $C$ ，使得 $P(X=C)=1$ 成立

2. 设 $X$ 为随机变量，$C$ 为常数，则

    $$
    D(CX) = C^2D(X)
    $$

3. 设 $X, Y$ 为独立随机变量，则

    $$
    D(X+Y) = D(X)+D(Y)
    $$

### 切比雪夫不等式

对于任意常数 $\epsilon > 0$，有

$$
P(|X - E(X)| \geq \epsilon) \leq \frac{D(X)}{\epsilon^2}
$$

## 常见分布的期望和方差

| |(0,1)分布|二项分布|泊松分布|均匀分布|指数分布|正态分布|
|---|---|---|---|---|---|---|
|$E(X)$|$p$|$np$|$\lambda$|$\frac{a+b}{2}$|$\frac{1}{\lambda}$|$\mu$|
|$D(X)$|$p(1-p)$|$np(1-p)$|$\lambda$|$\frac{(b-a)^2}{12}$|$\frac{1}{\lambda^2}$|$\sigma^2$|


## 协方差、相关系数和矩
- 协方差

    对于二维随机变量 $(X,Y)$，其协方差为

    $$
    Cov(X,Y) = E[(X - E(X))(Y - E(Y))] = E(XY) - E(X)E(Y)
    $$

    基于协方差，对任意的随机变量 $X, Y$，有

    $$
    D(X + Y) = D(X) + D(Y) + 2Cov(X,Y) \\
    D(X - Y) = D(X) + D(Y) - 2Cov(X,Y)
    $$

- 协方差的性质
  - $Cov(X,X) = D(X)$
  - $Cov(X,C) = 0$，其中 $C$ 为常数
  - $Cov(X,Y) = Cov(Y,X)$
  - 对于任意常数 $a,b$，有 $Cov(aX, bY) = abCov(X,Y)$
  - $Cov(X+Y,Z) = Cov(X,Z) + Cov(Y,Z)$
  - 若 $X, Y$ 独立，则 $Cov(X,Y) = 0$
  
- 相关系数

    相关系数 $\rho_{XY}$ 定义为

    $$
    \rho_{XY} = \frac{Cov(X,Y)}{\sqrt{D(X)D(Y)}}
    $$

- 相关系数的性质
    - $|\rho_{XY}| \leq 1$
    - $\rho_{XY} \pm 1$ 的充要条件为 $X$ 和 $Y$ 完全正相关或负相关，即存在常数 $a, b$ 使得 $Y = aX + b$ 成立。
    - 对于二维正态分布，$X, Y$ 相互独立的充分必要条件是 $\rho_{XY} = 0$。


# 大数定律和中心极限定理

## 大数定律

- 依概率收敛

    对于一列独立同分布的随机变量 $X_1, X_2, \ldots, X_n$，若存在常数 $a$，使得对任意 $\epsilon > 0$，有

    $$
    \lim_{n \to \infty} P\left( |X_n-a|<\epsilon\right) = 1
    $$

    则称 $X_n$ 依概率收敛于 $a$。

- 切比雪夫大数定律

    设 $X_1, X_2, \ldots, X_n$ 为一列两两不相关的随机变量，且期望存在，方差有界，则对于任意 $\epsilon > 0$，有
    $$
    \lim_{n \to \infty} P\left(\left|\frac{1}{n}\sum_{i=1}^{n}(X_i - E(X_i))\right| < \epsilon\right) = 0
    $$

- 伯努利大数定律

    设 $\mu_n$ 为 $n$ 重伯努利试验中事件 $A$ 出现的次数，又设 $p$ 为事件 $A$ 的成功概率，则对于任意 $\epsilon > 0$，有

    $$
    \lim_{n \to \infty} P\left(\left| \frac{\mu_n}{n} - p \right| < \epsilon\right) = 1
    $$

- 辛钦大数定律

    设 $X_1, X_2, \ldots, X_n$ 为一列独立同分布的随机变量，且 $E(X_i)=\mu$，则对于任意 $\epsilon > 0$，有

    $$
    \lim_{n \to \infty} P\left(\left| \frac{1}{n}\sum_{i=1}^{n}X_i - \mu \right| < \epsilon\right) = 1
    $$

## 中心极限定理

设 $X_1, X_2, \ldots, X_n$ 为一列独立同分布的随机变量，且其期望和方差均存在,则

$$
\sum_{i=1}^nX_i \to N(E(\sum_{i=1}^{n}X_i), D(\sum_{i=1}^{n}X_i))
$$

- 独立同分布中心极限定理

    设 $X_1, X_2, \ldots, X_n$ 为一列独立同分布的随机变量，且其期望和方差均存在，记

    $$
    Y_n = \frac{\sum_{i=1}^{n}X_i - \sum_{i=1}^{n}E(X)}{\sqrt{\sum_{i=1}^{n}D(X_i)}} \to N(0,1)    
    $$

    则 $Y_n$ 的分布函数 $F_n(x)$ 满足

    $$
    \lim_{n \to \infty} F_n(x) = \Phi(x)
    $$

    其中 $\Phi(x)$ 为标准正态分布的分布函数。

- 德莫佛-拉普拉斯中心极限定理

    设 $\mu_n$ 为 $n$ 重伯努利试验中事件 $A$ 出现的次数，又设 $p$ 为事件 $A$ 的成功概率，则对于任意 $\epsilon > 0$，有

    $$
    \lim_{n \to \infty} P\left(\frac{\mu_n - np}{\sqrt{np(1-p)}} < x\right) = \Phi(x)
    $$